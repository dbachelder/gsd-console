---
phase: 05-test-coverage
plan: 10
type: execute
wave: 7
depends_on: [05-02, 05-03, 05-04, 05-05, 05-06, 05-07, 05-08, 05-09]
files_modified:
  - coverage/
autonomous: true
must_haves:
  truths:
    - "All tests pass consistently (run 3x, no failures)"
    - "Line coverage reaches 80% or higher"
    - "No flaky tests (timing issues, race conditions)"
    - "Parser functions have comprehensive test coverage"
    - "Hook functions have test coverage where feasible"
  artifacts:
    - path: coverage/
      provides: "Coverage report directory"
      contains: "lcov.info"
  key_links:
    - from: Phase 5 success criteria
      to: coverage report
      via: "bun test --coverage"
      pattern: "coverageThreshold.*0\\.8"
---

<objective>
Verify all Phase 5 success criteria: consistent passing tests, 80%+ line coverage, no flaky tests, comprehensive parser and hook coverage.

Purpose: Final verification that test coverage meets Phase 5 goal. Run full test suite multiple times to check for flakiness. Review coverage report to identify any remaining gaps. Remove or fix flaky tests.

Output: All tests passing, 80%+ coverage, no flaky tests documented.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/05-test-coverage/05-RESEARCH.md
@bunfig.toml
@.planning/phases/05-test-coverage/05-02-SUMMARY.md
@.planning/phases/05-test-coverage/05-03-SUMMARY.md
@.planning/phases/05-test-coverage/05-04-SUMMARY.md
@.planning/phases/05-test-coverage/05-05-SUMMARY.md
@.planning/phases/05-test-coverage/05-06-SUMMARY.md
@.planning/phases/05-test-coverage/05-07-SUMMARY.md
@.planning/phases/05-test-coverage/05-08-SUMMARY.md
@.planning/phases/05-test-coverage/05-09-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Run full test suite 3 times to check for flakiness</name>
  <files>coverage/</files>
  <action>
    Run test suite 3 times to ensure no flaky tests:

    ```bash
    for i in 1 2 3; do
      echo "=== Run $i ==="
      bun test || exit 1
    done
    ```

    If any run fails:
    1. Identify failing test
    2. Check for timing issues (setTimeout, debouncing, async operations)
    3. Add proper await/delays to fix race conditions
    4. Re-run to verify fix

    Common flaky test causes (from 05-RESEARCH.md Pitfalls):
    - Hook tests not waiting for re-renders (Pitfall 3)
    - File watcher tests not waiting for debounce (Pitfall 1 timing)
    - memfs not reset between tests (Pitfall 2)
  </action>
  <verify>for i in 1 2 3; do bun test > /dev/null 2>&1 || echo "Run $i failed"; done | grep -c "failed" | xargs test 0 -eq</verify>
  <done>All 3 test runs pass without failures</done>
</task>

<task type="auto">
  <name>Generate and review coverage report</name>
  <files>coverage/</files>
  <action>
    Generate coverage report:

    ```bash
    bun test --coverage
    ```

    Review coverage report:
    1. Check overall line coverage is >= 80%
    2. Check parser.ts coverage (should be 80%+)
    3. Check hooks coverage (target 75%+ for complex hooks)
    4. Check component coverage (target 70%+ for layout/core components)
    5. Identify any files with < 60% coverage
    6. Review uncovered lines to identify missing test cases

    If coverage < 80%:
    1. Identify files with lowest coverage
    2. Add tests for uncovered branches
    3. Focus on parser functions and core hooks (highest priority)
    4. Re-run coverage to verify improvement

    If parser.ts coverage < 80%:
    1. Review uncovered lines in parseRoadmap, parseState, parseTodos
    2. Add edge case tests (malformed input, missing data)
    3. Test helper functions (findPhaseDirectory, scanPhaseDirectory)
    4. Follow Pitfall 4 from research: explicitly test error paths
  </action>
  <verify>bun test --coverage 2>&1 | grep "All files" | awk '{print $3}' | sed 's/%//' | awk '{print $1 >= 80}' | xargs test 1 -eq</verify>
  <done>Overall coverage >= 80%, parser coverage >= 80%</done>
</task>

<task type="auto">
  <name>Document remaining uncovered lines (if any)</name>
  <files>coverage/</files>
  <action>
    If any uncovered lines remain after reaching 80% threshold:

    1. Create note in 05-10-SUMMARY.md documenting:
       - Files with uncovered lines
       - Reason for not testing (if justifiable: e.g., third-party code, unreachable error paths)
       - Whether additional tests would add value

    2. Acceptable reasons for not testing:
       - Platform-specific code (e.g., terminal resize - from Open Question 3)
       - Third-party library integration already tested by library
       - Unreachable error paths (defensive code with no trigger)
       - UI polish/visual-only code (colors, styling)

    3. NOT acceptable reasons:
       - "Too hard to mock" - use memfs, vi.mock (Pitfall 5)
       - "Implementation detail" - test behavior, not internals
       - "Rare edge case" - add test anyway for robustness
  </action>
  <verify>grep -c "Uncovered" .planning/phases/05-test-coverage/05-10-SUMMARY.md 2>/dev/null || echo "0"</verify>
  <done>Uncovered lines documented with justification (if any)</done>
</task>

</tasks>

<verification>
Run `bun test --coverage` - overall coverage must be >= 80%.
Run `for i in 1 2 3; do bun test || exit 1; done` - all 3 runs must pass.
Check src/lib/parser.ts coverage in report - must be >= 80%.
Check hooks coverage in report - should be >= 75% for core hooks.
</verification>

<success_criteria>
- All tests pass 3 consecutive runs (no flaky tests)
- Overall line coverage >= 80%
- Parser functions (parseRoadmap, parseState, parseTodos) >= 80% coverage
- Hook functions have comprehensive coverage (>= 75% for core hooks)
- Uncovered lines documented with justification (if any remain)
- Phase 5 success criteria 1-5 all met
</success_criteria>

<output>
After completion, create `.planning/phases/05-test-coverage/05-10-SUMMARY.md`
</output>
